{
  
    
        "post0": {
            "title": "Telecom Churn Prediction",
            "content": "import numpy as np import pandas as pd import matplotlib.pyplot as plt import seaborn as sns . train = pd.read_csv(&#39;C: Users HP Downloads archive (98) cell2celltrain.csv&#39;) . test = pd.read_csv(&#39;C: Users HP Downloads archive (98) cell2cellholdout.csv&#39;) . train.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 51047 entries, 0 to 51046 Data columns (total 58 columns): # Column Non-Null Count Dtype -- -- 0 CustomerID 51047 non-null int64 1 Churn 51047 non-null object 2 MonthlyRevenue 50891 non-null float64 3 MonthlyMinutes 50891 non-null float64 4 TotalRecurringCharge 50891 non-null float64 5 DirectorAssistedCalls 50891 non-null float64 6 OverageMinutes 50891 non-null float64 7 RoamingCalls 50891 non-null float64 8 PercChangeMinutes 50680 non-null float64 9 PercChangeRevenues 50680 non-null float64 10 DroppedCalls 51047 non-null float64 11 BlockedCalls 51047 non-null float64 12 UnansweredCalls 51047 non-null float64 13 CustomerCareCalls 51047 non-null float64 14 ThreewayCalls 51047 non-null float64 15 ReceivedCalls 51047 non-null float64 16 OutboundCalls 51047 non-null float64 17 InboundCalls 51047 non-null float64 18 PeakCallsInOut 51047 non-null float64 19 OffPeakCallsInOut 51047 non-null float64 20 DroppedBlockedCalls 51047 non-null float64 21 CallForwardingCalls 51047 non-null float64 22 CallWaitingCalls 51047 non-null float64 23 MonthsInService 51047 non-null int64 24 UniqueSubs 51047 non-null int64 25 ActiveSubs 51047 non-null int64 26 ServiceArea 51023 non-null object 27 Handsets 51046 non-null float64 28 HandsetModels 51046 non-null float64 29 CurrentEquipmentDays 51046 non-null float64 30 AgeHH1 50138 non-null float64 31 AgeHH2 50138 non-null float64 32 ChildrenInHH 51047 non-null object 33 HandsetRefurbished 51047 non-null object 34 HandsetWebCapable 51047 non-null object 35 TruckOwner 51047 non-null object 36 RVOwner 51047 non-null object 37 Homeownership 51047 non-null object 38 BuysViaMailOrder 51047 non-null object 39 RespondsToMailOffers 51047 non-null object 40 OptOutMailings 51047 non-null object 41 NonUSTravel 51047 non-null object 42 OwnsComputer 51047 non-null object 43 HasCreditCard 51047 non-null object 44 RetentionCalls 51047 non-null int64 45 RetentionOffersAccepted 51047 non-null int64 46 NewCellphoneUser 51047 non-null object 47 NotNewCellphoneUser 51047 non-null object 48 ReferralsMadeBySubscriber 51047 non-null int64 49 IncomeGroup 51047 non-null int64 50 OwnsMotorcycle 51047 non-null object 51 AdjustmentsToCreditRating 51047 non-null int64 52 HandsetPrice 51047 non-null object 53 MadeCallToRetentionTeam 51047 non-null object 54 CreditRating 51047 non-null object 55 PrizmCode 51047 non-null object 56 Occupation 51047 non-null object 57 MaritalStatus 51047 non-null object dtypes: float64(26), int64(9), object(23) memory usage: 22.6+ MB . test.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 20000 entries, 0 to 19999 Data columns (total 58 columns): # Column Non-Null Count Dtype -- -- 0 CustomerID 20000 non-null int64 1 Churn 0 non-null float64 2 MonthlyRevenue 19940 non-null float64 3 MonthlyMinutes 19940 non-null float64 4 TotalRecurringCharge 19940 non-null float64 5 DirectorAssistedCalls 19940 non-null float64 6 OverageMinutes 19940 non-null float64 7 RoamingCalls 19940 non-null float64 8 PercChangeMinutes 19865 non-null float64 9 PercChangeRevenues 19865 non-null float64 10 DroppedCalls 20000 non-null float64 11 BlockedCalls 20000 non-null float64 12 UnansweredCalls 20000 non-null float64 13 CustomerCareCalls 20000 non-null float64 14 ThreewayCalls 20000 non-null float64 15 ReceivedCalls 20000 non-null float64 16 OutboundCalls 20000 non-null float64 17 InboundCalls 20000 non-null float64 18 PeakCallsInOut 20000 non-null float64 19 OffPeakCallsInOut 20000 non-null float64 20 DroppedBlockedCalls 20000 non-null float64 21 CallForwardingCalls 20000 non-null float64 22 CallWaitingCalls 20000 non-null float64 23 MonthsInService 20000 non-null int64 24 UniqueSubs 20000 non-null int64 25 ActiveSubs 20000 non-null int64 26 ServiceArea 19996 non-null object 27 Handsets 20000 non-null int64 28 HandsetModels 20000 non-null int64 29 CurrentEquipmentDays 20000 non-null int64 30 AgeHH1 19665 non-null float64 31 AgeHH2 19665 non-null float64 32 ChildrenInHH 20000 non-null object 33 HandsetRefurbished 20000 non-null object 34 HandsetWebCapable 20000 non-null object 35 TruckOwner 20000 non-null object 36 RVOwner 20000 non-null object 37 Homeownership 20000 non-null object 38 BuysViaMailOrder 20000 non-null object 39 RespondsToMailOffers 20000 non-null object 40 OptOutMailings 20000 non-null object 41 NonUSTravel 20000 non-null object 42 OwnsComputer 20000 non-null object 43 HasCreditCard 20000 non-null object 44 RetentionCalls 20000 non-null int64 45 RetentionOffersAccepted 20000 non-null int64 46 NewCellphoneUser 20000 non-null object 47 NotNewCellphoneUser 20000 non-null object 48 ReferralsMadeBySubscriber 20000 non-null int64 49 IncomeGroup 20000 non-null int64 50 OwnsMotorcycle 20000 non-null object 51 AdjustmentsToCreditRating 20000 non-null int64 52 HandsetPrice 20000 non-null object 53 MadeCallToRetentionTeam 20000 non-null object 54 CreditRating 20000 non-null object 55 PrizmCode 20000 non-null object 56 Occupation 20000 non-null object 57 MaritalStatus 20000 non-null object dtypes: float64(24), int64(12), object(22) memory usage: 8.9+ MB . numeric = train.select_dtypes(include=[np.number]) . categorical = train.select_dtypes(exclude=[np.number]) . categorical . Churn ServiceArea ChildrenInHH HandsetRefurbished HandsetWebCapable TruckOwner RVOwner Homeownership BuysViaMailOrder RespondsToMailOffers ... HasCreditCard NewCellphoneUser NotNewCellphoneUser OwnsMotorcycle HandsetPrice MadeCallToRetentionTeam CreditRating PrizmCode Occupation MaritalStatus . 0 Yes | SEAPOR503 | No | No | Yes | No | No | Known | Yes | Yes | ... | Yes | No | No | No | 30 | Yes | 1-Highest | Suburban | Professional | No | . 1 Yes | PITHOM412 | Yes | No | No | No | No | Known | Yes | Yes | ... | Yes | Yes | No | No | 30 | No | 4-Medium | Suburban | Professional | Yes | . 2 No | MILMIL414 | Yes | No | No | No | No | Unknown | No | No | ... | Yes | Yes | No | No | Unknown | No | 3-Good | Town | Crafts | Yes | . 3 No | PITHOM412 | No | No | Yes | No | No | Known | Yes | Yes | ... | Yes | Yes | No | No | 10 | No | 4-Medium | Other | Other | No | . 4 Yes | OKCTUL918 | No | No | No | No | No | Known | Yes | Yes | ... | Yes | No | Yes | No | 10 | No | 1-Highest | Other | Professional | Yes | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 51042 Yes | LAXSFN818 | No | Yes | Yes | No | No | Known | Yes | Yes | ... | Yes | No | No | No | 60 | No | 1-Highest | Suburban | Other | Yes | . 51043 No | LAXCDG310 | Yes | No | Yes | No | No | Known | Yes | Yes | ... | Yes | No | No | No | 60 | No | 3-Good | Other | Other | No | . 51044 Yes | LAXCDG310 | No | No | Yes | No | No | Known | No | No | ... | Yes | No | No | No | 80 | No | 5-Low | Other | Clerical | No | . 51045 No | NEVPOW619 | Yes | No | Yes | No | No | Unknown | No | No | ... | No | No | No | No | 30 | No | 5-Low | Other | Other | No | . 51046 No | NEVPOW619 | No | No | Yes | No | No | Unknown | No | No | ... | No | No | No | No | 60 | Yes | 5-Low | Other | Other | Unknown | . 51047 rows × 23 columns . numeric . CustomerID MonthlyRevenue MonthlyMinutes TotalRecurringCharge DirectorAssistedCalls OverageMinutes RoamingCalls PercChangeMinutes PercChangeRevenues DroppedCalls ... Handsets HandsetModels CurrentEquipmentDays AgeHH1 AgeHH2 RetentionCalls RetentionOffersAccepted ReferralsMadeBySubscriber IncomeGroup AdjustmentsToCreditRating . 0 3000002 | 24.00 | 219.0 | 22.0 | 0.25 | 0.0 | 0.0 | -157.0 | -19.0 | 0.7 | ... | 2.0 | 2.0 | 361.0 | 62.0 | 0.0 | 1 | 0 | 0 | 4 | 0 | . 1 3000010 | 16.99 | 10.0 | 17.0 | 0.00 | 0.0 | 0.0 | -4.0 | 0.0 | 0.3 | ... | 2.0 | 1.0 | 1504.0 | 40.0 | 42.0 | 0 | 0 | 0 | 5 | 0 | . 2 3000014 | 38.00 | 8.0 | 38.0 | 0.00 | 0.0 | 0.0 | -2.0 | 0.0 | 0.0 | ... | 1.0 | 1.0 | 1812.0 | 26.0 | 26.0 | 0 | 0 | 0 | 6 | 0 | . 3 3000022 | 82.28 | 1312.0 | 75.0 | 1.24 | 0.0 | 0.0 | 157.0 | 8.1 | 52.0 | ... | 9.0 | 4.0 | 458.0 | 30.0 | 0.0 | 0 | 0 | 0 | 6 | 0 | . 4 3000026 | 17.14 | 0.0 | 17.0 | 0.00 | 0.0 | 0.0 | 0.0 | -0.2 | 0.0 | ... | 4.0 | 3.0 | 852.0 | 46.0 | 54.0 | 0 | 0 | 0 | 9 | 1 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 51042 3399958 | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | 9.3 | ... | 2.0 | 2.0 | 526.0 | 68.0 | 64.0 | 0 | 0 | 0 | 6 | 0 | . 51043 3399974 | 95.17 | 1745.0 | 85.0 | 0.99 | 45.0 | 4.7 | 122.0 | 15.9 | 16.7 | ... | 2.0 | 2.0 | 464.0 | 48.0 | 48.0 | 0 | 0 | 0 | 9 | 1 | . 51044 3399978 | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | 71.7 | ... | 3.0 | 2.0 | 378.0 | 36.0 | 0.0 | 0 | 0 | 0 | 7 | 1 | . 51045 3399990 | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | 0.0 | ... | 2.0 | 2.0 | 433.0 | 32.0 | 0.0 | 0 | 0 | 0 | 9 | 0 | . 51046 3399994 | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | 18.7 | ... | 7.0 | 5.0 | 75.0 | 0.0 | 0.0 | 2 | 1 | 0 | 0 | 1 | . 51047 rows × 35 columns . EDA . plt.figure(figsize=(8,4),dpi=120) sns.scatterplot(data=train,y=&#39;MonthlyRevenue&#39;,x=&#39;MonthlyMinutes&#39;,alpha=0.7) . &lt;AxesSubplot:xlabel=&#39;MonthlyMinutes&#39;, ylabel=&#39;MonthlyRevenue&#39;&gt; . plt.figure(figsize=(8,4),dpi=120) sns.scatterplot(data=train,x=&#39;MonthlyMinutes&#39;,y=&#39;MonthlyRevenue&#39;,hue=&#39;Churn&#39;,alpha=0.7) . &lt;AxesSubplot:xlabel=&#39;MonthlyMinutes&#39;, ylabel=&#39;MonthlyRevenue&#39;&gt; . plt.figure(figsize=(8,4),dpi=120) sns.scatterplot(data=train,x=&#39;MonthlyMinutes&#39;,y=&#39;MonthlyRevenue&#39;,hue=&#39;Churn&#39;,alpha=0.7) plt.xlim(3000) . (3000.0, 7726.95) . Customers with more monthly minutes are less likely to churn out. . plt.figure(figsize=(8,4),dpi=120) sns.histplot(data=test,x=&#39;MonthsInService&#39;,kde=&#39;True&#39;) . &lt;AxesSubplot:xlabel=&#39;MonthsInService&#39;, ylabel=&#39;Count&#39;&gt; . plt.figure(figsize=(8,4),dpi=120) sns.boxplot(data=train,x=&#39;MonthsInService&#39;) . &lt;AxesSubplot:xlabel=&#39;MonthsInService&#39;&gt; . def duration(months): if months &lt;= 10: return &#39;Less than one year&#39; elif months &gt;10 and months &lt;=20: return &#39;Less than two years&#39; elif months &gt;20 and months &lt;= 30: return &#39;Less than three years&#39; elif months &gt; 30 and months &lt;= 40: return &#39;Less than four years&#39; elif months &gt; 40 and months &lt;= 50: return &#39;Less than five years&#39; elif months &gt; 50 and months &lt;= 60: return &#39;Less than six years&#39; elif months &gt; 60 and months &lt;= 70: return &#39;Less then seven years&#39; train[&#39;Subscription_months&#39;] = train[&#39;MonthsInService&#39;].apply(duration) test[&#39;Subscription_months&#39;] = test[&#39;MonthsInService&#39;].apply(duration) . train[&#39;Subscription_months&#39;].value_counts().sort_values() . Less then seven years 1 Less than six years 387 Less than five years 1365 Less than four years 4989 Less than one year 10639 Less than three years 11996 Less than two years 21670 Name: Subscription_months, dtype: int64 . train[&#39;Occupation&#39;].value_counts() . Other 37637 Professional 8755 Crafts 1519 Clerical 986 Self 879 Retired 733 Student 381 Homemaker 157 Name: Occupation, dtype: int64 . plt.figure(figsize=(8,4),dpi=120) sns.countplot(data=train,x=&#39;Occupation&#39;) . &lt;AxesSubplot:xlabel=&#39;Occupation&#39;, ylabel=&#39;count&#39;&gt; . plt.figure(figsize=(8,4),dpi=120) sns.barplot(data=train,x=&#39;Occupation&#39;,y=&#39;MonthlyRevenue&#39;,estimator=np.mean) . &lt;AxesSubplot:xlabel=&#39;Occupation&#39;, ylabel=&#39;MonthlyRevenue&#39;&gt; . Lowest revenue is generated from Retired category, and other categories have a fair distribution in generating revenue. . plt.figure(figsize=(8,6),dpi=120) sns.barplot(data=train,x=&#39;Subscription_months&#39;,y=&#39;MonthlyRevenue&#39;,estimator=np.mean) plt.xticks(rotation=90); . Fair distribution of monthly revenue generated. . train[&#39;CreditRating&#39;].value_counts().sort_values() . 6-VeryLow 1152 7-Lowest 2114 4-Medium 5357 5-Low 6499 3-Good 8410 1-Highest 8522 2-High 18993 Name: CreditRating, dtype: int64 . train[&#39;IncomeGroup&#39;].value_counts() . 0 12835 6 9607 7 5877 9 5563 5 4262 4 4053 3 2991 8 2622 1 2039 2 1198 Name: IncomeGroup, dtype: int64 . plt.figure(figsize=(8,6),dpi=120) sns.barplot(data=train,x=&#39;IncomeGroup&#39;,y=&#39;MonthlyRevenue&#39;,estimator=np.mean) plt.xticks(rotation=90); . All Income groups contribute fairly to monthly revenue . plt.figure(figsize=(8,6),dpi=120) sns.barplot(data=train,x=&#39;CreditRating&#39;,y=&#39;MonthlyRevenue&#39;,estimator=np.mean) plt.xticks(rotation=90); . Low credit ratings contribute more to monthly revenue . category_col = list(categorical.columns) . category_col.remove(&#39;Churn&#39;) . train.isnull().sum() . CustomerID 0 Churn 0 MonthlyRevenue 156 MonthlyMinutes 156 TotalRecurringCharge 156 DirectorAssistedCalls 156 OverageMinutes 156 RoamingCalls 156 PercChangeMinutes 367 PercChangeRevenues 367 DroppedCalls 0 BlockedCalls 0 UnansweredCalls 0 CustomerCareCalls 0 ThreewayCalls 0 ReceivedCalls 0 OutboundCalls 0 InboundCalls 0 PeakCallsInOut 0 OffPeakCallsInOut 0 DroppedBlockedCalls 0 CallForwardingCalls 0 CallWaitingCalls 0 MonthsInService 0 UniqueSubs 0 ActiveSubs 0 ServiceArea 24 Handsets 1 HandsetModels 1 CurrentEquipmentDays 1 AgeHH1 909 AgeHH2 909 ChildrenInHH 0 HandsetRefurbished 0 HandsetWebCapable 0 TruckOwner 0 RVOwner 0 Homeownership 0 BuysViaMailOrder 0 RespondsToMailOffers 0 OptOutMailings 0 NonUSTravel 0 OwnsComputer 0 HasCreditCard 0 RetentionCalls 0 RetentionOffersAccepted 0 NewCellphoneUser 0 NotNewCellphoneUser 0 ReferralsMadeBySubscriber 0 IncomeGroup 0 OwnsMotorcycle 0 AdjustmentsToCreditRating 0 HandsetPrice 0 MadeCallToRetentionTeam 0 CreditRating 0 PrizmCode 0 Occupation 0 MaritalStatus 0 Subscription_months 0 dtype: int64 . train[(train[&#39;MonthlyRevenue&#39;].isnull()) &amp; (train[&#39;Churn&#39;]==&#39;Yes&#39;)] . CustomerID Churn MonthlyRevenue MonthlyMinutes TotalRecurringCharge DirectorAssistedCalls OverageMinutes RoamingCalls PercChangeMinutes PercChangeRevenues ... IncomeGroup OwnsMotorcycle AdjustmentsToCreditRating HandsetPrice MadeCallToRetentionTeam CreditRating PrizmCode Occupation MaritalStatus Subscription_months . 122 3000898 | Yes | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | ... | 5 | No | 0 | 30 | No | 1-Highest | Other | Other | No | Less than six years | . 126 3000926 | Yes | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | ... | 1 | No | 0 | 30 | No | 1-Highest | Town | Other | Unknown | Less than five years | . 925 3007326 | Yes | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | ... | 4 | No | 0 | 60 | No | 3-Good | Other | Self | Yes | Less than five years | . 1454 3011438 | Yes | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | ... | 5 | No | 1 | 30 | No | 1-Highest | Other | Other | Yes | Less than five years | . 2228 3017394 | Yes | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | ... | 6 | No | 0 | Unknown | No | 5-Low | Suburban | Other | Yes | Less than four years | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 51010 3399690 | Yes | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | ... | 4 | No | 0 | 60 | No | 3-Good | Other | Other | Yes | Less than four years | . 51011 3399698 | Yes | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | ... | 6 | No | 0 | Unknown | No | 1-Highest | Other | Other | No | Less than four years | . 51026 3399830 | Yes | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | ... | 9 | No | 0 | Unknown | No | 1-Highest | Suburban | Other | Unknown | Less than three years | . 51042 3399958 | Yes | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | ... | 6 | No | 0 | 60 | No | 1-Highest | Suburban | Other | Yes | Less than three years | . 51044 3399978 | Yes | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | ... | 7 | No | 1 | 80 | No | 5-Low | Other | Clerical | No | Less than three years | . 70 rows × 59 columns . train[train[&#39;PercChangeMinutes&#39;].isnull()] . CustomerID Churn MonthlyRevenue MonthlyMinutes TotalRecurringCharge DirectorAssistedCalls OverageMinutes RoamingCalls PercChangeMinutes PercChangeRevenues ... IncomeGroup OwnsMotorcycle AdjustmentsToCreditRating HandsetPrice MadeCallToRetentionTeam CreditRating PrizmCode Occupation MaritalStatus Subscription_months . 91 3000626 | No | 96.04 | 545.0 | 60.0 | 0.66 | 111.0 | 1.1 | NaN | NaN | ... | 0 | No | 0 | 60 | No | 1-Highest | Town | Other | Unknown | Less than six years | . 122 3000898 | Yes | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | ... | 5 | No | 0 | 30 | No | 1-Highest | Other | Other | No | Less than six years | . 126 3000926 | Yes | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | ... | 1 | No | 0 | 30 | No | 1-Highest | Town | Other | Unknown | Less than five years | . 461 3003534 | No | 52.85 | 662.0 | 57.0 | 0.33 | 0.0 | 5.0 | NaN | NaN | ... | 6 | No | 0 | 150 | Yes | 1-Highest | Suburban | Other | Unknown | Less than five years | . 641 3005090 | Yes | 5.00 | 0.0 | 0.0 | 0.00 | 0.0 | 0.0 | NaN | NaN | ... | 9 | No | 0 | Unknown | No | 3-Good | Suburban | Other | Yes | Less than five years | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 51038 3399910 | No | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | ... | 7 | No | 0 | 30 | No | 1-Highest | Suburban | Other | Unknown | Less than three years | . 51042 3399958 | Yes | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | ... | 6 | No | 0 | 60 | No | 1-Highest | Suburban | Other | Yes | Less than three years | . 51044 3399978 | Yes | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | ... | 7 | No | 1 | 80 | No | 5-Low | Other | Clerical | No | Less than three years | . 51045 3399990 | No | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | ... | 9 | No | 0 | 30 | No | 5-Low | Other | Other | No | Less than four years | . 51046 3399994 | No | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | ... | 0 | No | 1 | 60 | Yes | 5-Low | Other | Other | Unknown | Less than three years | . 367 rows × 59 columns . Feature Engineering and Feature Selection . train.dropna(axis=0,inplace=True) test.dropna(axis=0,inplace=True) . X = train.drop(&#39;Churn&#39;,axis=1) y = train[&#39;Churn&#39;] . from sklearn.model_selection import train_test_split X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=101) . category_col.append(&#39;Subscription_months&#39;) . from feature_engine.encoding import OrdinalEncoder ordinal_encoder = OrdinalEncoder(variables=category_col) . y.replace([&#39;Yes&#39;,&#39;No&#39;],value=[1,0],inplace=True) . ordinal_encoder.fit(X_train,y_train) . OrdinalEncoder(variables=[&#39;ServiceArea&#39;, &#39;ChildrenInHH&#39;, &#39;HandsetRefurbished&#39;, &#39;HandsetWebCapable&#39;, &#39;TruckOwner&#39;, &#39;RVOwner&#39;, &#39;Homeownership&#39;, &#39;BuysViaMailOrder&#39;, &#39;RespondsToMailOffers&#39;, &#39;OptOutMailings&#39;, &#39;NonUSTravel&#39;, &#39;OwnsComputer&#39;, &#39;HasCreditCard&#39;, &#39;NewCellphoneUser&#39;, &#39;NotNewCellphoneUser&#39;, &#39;OwnsMotorcycle&#39;, &#39;HandsetPrice&#39;, &#39;MadeCallToRetentionTeam&#39;, &#39;CreditRating&#39;, &#39;PrizmCode&#39;, &#39;Occupation&#39;, &#39;MaritalStatus&#39;, &#39;Subscription_months&#39;, &#39;Subscription_months&#39;]) . X_train = ordinal_encoder.transform(X_train) X_test = ordinal_encoder.transform(X_test) . C: Users HP Downloads Anaconda_new lib site-packages feature_engine encoding base_encoder.py:193: UserWarning: During the encoding, NaN values were introduced in the feature(s) ServiceArea. warnings.warn( . from feature_engine.selection import DropConstantFeatures as dc from feature_engine.selection import DropDuplicateFeatures as ddup . sel = dc(tol=0.99) . sel.fit(X_train) . DropConstantFeatures(tol=0.99) . sel.features_to_drop_ . [&#39;CallForwardingCalls&#39;] . X_train = sel.transform(X_train) X_test = sel.transform(X_test) . sel = ddup() sel.fit(X_train) . DropDuplicateFeatures() . X_train = sel.transform(X_train) X_test = sel.transform(X_test) . from sklearn.ensemble import RandomForestClassifier from feature_engine.selection import SmartCorrelatedSelection as SCS . rf = RandomForestClassifier() sel = SCS(threshold=0.8,estimator=rf,cv=3) sel.fit(X_train,y_train) . SmartCorrelatedSelection(estimator=RandomForestClassifier()) . sel.features_to_drop_ . [&#39;ReceivedCalls&#39;, &#39;DroppedBlockedCalls&#39;, &#39;Handsets&#39;, &#39;BuysViaMailOrder&#39;, &#39;RetentionCalls&#39;] . sel.correlated_feature_sets_ . [{&#39;MonthlyMinutes&#39;, &#39;ReceivedCalls&#39;}, {&#39;BlockedCalls&#39;, &#39;DroppedBlockedCalls&#39;}, {&#39;HandsetModels&#39;, &#39;Handsets&#39;}, {&#39;BuysViaMailOrder&#39;, &#39;RespondsToMailOffers&#39;}, {&#39;MadeCallToRetentionTeam&#39;, &#39;RetentionCalls&#39;}] . X_train = sel.transform(X_train) X_test = sel.transform(X_test) . X_trainn = X_train . from sklearn.feature_selection import SelectKBest, chi2, mutual_info_classif . sel = SelectKBest(mutual_info_classif,k=20) . sel.fit(X_trainn,y_train) . SelectKBest(k=20, score_func=&lt;function mutual_info_classif at 0x0000022DCDBDAEE0&gt;) . . len(X_trainn) . 34826 . Model Building with 20 features . from sklearn.ensemble import RandomForestClassifier rfc = RandomForestClassifier() rfc.fit(X_train,y_train) . RandomForestClassifier() . rfc.feature_importances_ . array([0.04324872, 0.04047243, 0.04415805, 0.02816982, 0.01913889, 0.02440732, 0.01777274, 0.04602329, 0.03987401, 0.02777594, 0.02439108, 0.03352194, 0.01785917, 0.01024026, 0.03352286, 0.03185418, 0.02556385, 0.03466126, 0.03417809, 0.02947202, 0.00039164, 0.01597521, 0.03362669, 0.01107025, 0.00723789, 0.05509813, 0.00857872, 0.0069422 , 0.05325307, 0.02587271, 0.01862945, 0.00472835, 0.00464484, 0.00437891, 0.00421204, 0.0030057 , 0.00410281, 0.00412669, 0.00422763, 0.00126183, 0.0026187 , 0.00419523, 0.00395904, 0.00238723, 0.00093804, 0.00515096, 0.00436182, 0.00254065, 0.01891934, 0.00104458, 0.00206343, 0.01113174, 0.00231694, 0.01694146, 0.01282859, 0.0084616 , 0.00865103, 0.01381896]) . pred = rfc.predict(X_test) . Metrics for prediction . from sklearn.metrics import confusion_matrix, f1_score, classification_report . len(y_test) . 14890 . len(pred) . 14890 . confusion_matrix(y_test,pred) . array([[10335, 323], [ 3873, 359]], dtype=int64) . print(classification_report(y_test,pred)) . precision recall f1-score support 0 0.73 0.97 0.83 10658 1 0.53 0.08 0.15 4232 accuracy 0.72 14890 macro avg 0.63 0.53 0.49 14890 weighted avg 0.67 0.72 0.64 14890 . rfc_score = rfc.score(X_test,y_test) print(rfc_score) . 0.7182001343183344 . from sklearn.metrics import roc_curve pred_curve = rfc.predict_proba(X_test) curve = pred_curve[:,1] fpr, tpr, thresholds = roc_curve(y_test, curve) plt.subplot(331) plt.plot([0,1],[0,1],&#39;k--&#39;) plt.plot(fpr,tpr, label=&#39;ANN&#39;) plt.xlabel(&#39;fpr&#39;) plt.ylabel(&#39;tpr&#39;) plt.title(&#39;ROC Curve Random Forest&#39;) plt.grid(True) plt.subplots_adjust(top=2, bottom=0.08, left=0.10, right=1.4, hspace=0.45, wspace=0.45) plt.show() .",
            "url": "https://bilalkhan18.github.io/port/2022/09/15/Telecom_Churn.html",
            "relUrl": "/2022/09/15/Telecom_Churn.html",
            "date": " • Sep 15, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "Sine Wave prediction using RNN and LSTM",
            "content": "Imports . import numpy as np import pandas as pd import matplotlib.pyplot as plt import seaborn as sns . Creating dataset . x = np.linspace(0,50,501) y = np.sin(x) . plt.plot(x,y) . [&lt;matplotlib.lines.Line2D at 0x18d2e083c40&gt;] . np.sin(20) . 0.9129452507276277 . np.sin(10) . -0.5440211108893698 . df = pd.DataFrame(data=y,index=x,columns=[&#39;Sine&#39;]) . df . Sine . 0.0 0.000000 | . 0.1 0.099833 | . 0.2 0.198669 | . 0.3 0.295520 | . 0.4 0.389418 | . ... ... | . 49.6 -0.617439 | . 49.7 -0.535823 | . 49.8 -0.448854 | . 49.9 -0.357400 | . 50.0 -0.262375 | . 501 rows × 1 columns . 0.1*len(df) . 50.1 . train = df.iloc[:451] test = df.iloc[451:] . train . Sine . 0.0 0.000000 | . 0.1 0.099833 | . 0.2 0.198669 | . 0.3 0.295520 | . 0.4 0.389418 | . ... ... | . 44.6 0.579164 | . 44.7 0.657656 | . 44.8 0.729577 | . 44.9 0.794208 | . 45.0 0.850904 | . 451 rows × 1 columns . test.head() . Sine . 45.1 0.899097 | . 45.2 0.938307 | . 45.3 0.968142 | . 45.4 0.988304 | . 45.5 0.998591 | . Scaling and creating sequences using TimeseriesGenerator . from sklearn.preprocessing import MinMaxScaler scaler = MinMaxScaler() scaled_train = scaler.fit_transform(train) scaled_test = scaler.transform(test) . from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator . df.iloc[121] . Sine -0.449647 Name: 12.100000000000001, dtype: float64 . length = 120 n_features=1 . generator = TimeseriesGenerator(data=scaled_train,targets=scaled_train,length=length, batch_size=1) #validation_generator = TimeseriesGenerator(data=scaled_test,targets=scaled_test,length=length,batch_size=1) . generator[0] . (array([[[4.99999116e-01], [5.49916225e-01], [5.99334579e-01], [6.47760405e-01], [6.94709850e-01], [7.39713809e-01], [7.82322618e-01], [8.22110545e-01], [8.58680040e-01], [8.91665714e-01], [9.20737985e-01], [9.45606372e-01], [9.66022399e-01], [9.81782075e-01], [9.92727935e-01], [9.98750612e-01], [9.99789928e-01], [9.95835500e-01], [9.86926839e-01], [9.73152957e-01], [9.54651478e-01], [9.31607263e-01], [9.04250562e-01], [8.72854714e-01], [8.37733417e-01], [7.99237589e-01], [7.57751870e-01], [7.13690771e-01], [6.67494535e-01], [6.19624741e-01], [5.70559686e-01], [5.20789614e-01], [4.70811810e-01], [4.21125636e-01], [3.72227539e-01], [3.24606094e-01], [2.78737119e-01], [2.35078919e-01], [1.94067715e-01], [1.56113277e-01], [1.21594831e-01], [9.08572769e-02], [6.42077324e-02], [4.19124713e-02], [2.41942605e-02], [1.12301346e-02], [3.14962674e-03], [3.34747619e-05], [1.91281421e-03], [8.76886734e-03], [2.05331307e-02], [3.70880598e-02], [5.82682430e-02], [8.38620552e-02], [1.13613771e-01], [1.47226122e-01], [1.84363264e-01], [2.24654135e-01], [2.67696162e-01], [3.13059283e-01], [3.60290246e-01], [4.08917133e-01], [4.58454081e-01], [5.08406134e-01], [5.58274186e-01], [6.07559973e-01], [6.55771048e-01], [7.02425701e-01], [7.47057774e-01], [7.89221319e-01], [8.28495052e-01], [8.64486561e-01], [8.96836233e-01], [9.25220839e-01], [9.49356770e-01], [9.69002868e-01], [9.83962836e-01], [9.94087198e-01], [9.99274795e-01], [9.99473795e-01], [9.94682209e-01], [9.84947913e-01], [9.70368169e-01], [9.51088653e-01], [9.27301999e-01], [8.99245876e-01], [8.67200612e-01], [8.31486391e-01], [7.92460059e-01], [7.50511555e-01], [7.06060012e-01], [6.59549578e-01], [6.11444967e-01], [5.62226827e-01], [5.12386928e-01], [4.62423254e-01], [4.12835026e-01], [3.64117712e-01], [3.16758081e-01], [2.71229333e-01], [2.27986377e-01], [1.87461283e-01], [1.50058964e-01], [1.16153131e-01], [8.60825596e-02], [6.01477060e-02], [3.86077023e-02], [2.16777691e-02], [9.52706470e-03], [2.27699490e-03], [0.00000000e+00], [2.71883099e-03], [1.04063222e-02], [2.29856628e-02], [4.03311641e-02], [6.22695157e-02], [8.85815167e-02], [1.19004266e-01], [1.53233791e-01], [1.90928079e-01]]]), array([[0.2317105]])) . generator[1] . (array([[[5.49916225e-01], [5.99334579e-01], [6.47760405e-01], [6.94709850e-01], [7.39713809e-01], [7.82322618e-01], [8.22110545e-01], [8.58680040e-01], [8.91665714e-01], [9.20737985e-01], [9.45606372e-01], [9.66022399e-01], [9.81782075e-01], [9.92727935e-01], [9.98750612e-01], [9.99789928e-01], [9.95835500e-01], [9.86926839e-01], [9.73152957e-01], [9.54651478e-01], [9.31607263e-01], [9.04250562e-01], [8.72854714e-01], [8.37733417e-01], [7.99237589e-01], [7.57751870e-01], [7.13690771e-01], [6.67494535e-01], [6.19624741e-01], [5.70559686e-01], [5.20789614e-01], [4.70811810e-01], [4.21125636e-01], [3.72227539e-01], [3.24606094e-01], [2.78737119e-01], [2.35078919e-01], [1.94067715e-01], [1.56113277e-01], [1.21594831e-01], [9.08572769e-02], [6.42077324e-02], [4.19124713e-02], [2.41942605e-02], [1.12301346e-02], [3.14962674e-03], [3.34747619e-05], [1.91281421e-03], [8.76886734e-03], [2.05331307e-02], [3.70880598e-02], [5.82682430e-02], [8.38620552e-02], [1.13613771e-01], [1.47226122e-01], [1.84363264e-01], [2.24654135e-01], [2.67696162e-01], [3.13059283e-01], [3.60290246e-01], [4.08917133e-01], [4.58454081e-01], [5.08406134e-01], [5.58274186e-01], [6.07559973e-01], [6.55771048e-01], [7.02425701e-01], [7.47057774e-01], [7.89221319e-01], [8.28495052e-01], [8.64486561e-01], [8.96836233e-01], [9.25220839e-01], [9.49356770e-01], [9.69002868e-01], [9.83962836e-01], [9.94087198e-01], [9.99274795e-01], [9.99473795e-01], [9.94682209e-01], [9.84947913e-01], [9.70368169e-01], [9.51088653e-01], [9.27301999e-01], [8.99245876e-01], [8.67200612e-01], [8.31486391e-01], [7.92460059e-01], [7.50511555e-01], [7.06060012e-01], [6.59549578e-01], [6.11444967e-01], [5.62226827e-01], [5.12386928e-01], [4.62423254e-01], [4.12835026e-01], [3.64117712e-01], [3.16758081e-01], [2.71229333e-01], [2.27986377e-01], [1.87461283e-01], [1.50058964e-01], [1.16153131e-01], [8.60825596e-02], [6.01477060e-02], [3.86077023e-02], [2.16777691e-02], [9.52706470e-03], [2.27699490e-03], [0.00000000e+00], [2.71883099e-03], [1.04063222e-02], [2.29856628e-02], [4.03311641e-02], [6.22695157e-02], [8.85815167e-02], [1.19004266e-01], [1.53233791e-01], [1.90928079e-01], [2.31710504e-01]]]), array([[0.27517358]])) . . Creating RNN Model . from tensorflow.keras.models import Sequential from tensorflow.keras.layers import SimpleRNN,Dense from tensorflow.keras.callbacks import EarlyStopping . early_stop = EarlyStopping(patience=3) . model = Sequential() model.add(SimpleRNN(120,input_shape=(length,n_features))) model.add(Dense(1)) model.compile(optimizer=&#39;adam&#39;,loss=&#39;mse&#39;) . model.summary() . Model: &#34;sequential&#34; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= simple_rnn (SimpleRNN) (None, 120) 14640 dense (Dense) (None, 1) 121 ================================================================= Total params: 14,761 Trainable params: 14,761 Non-trainable params: 0 _________________________________________________________________ . model.fit(generator, epochs=8, callbacks=[early_stop]) . Epoch 1/8 331/331 [==============================] - ETA: 0s - loss: 0.0023WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss 331/331 [==============================] - 18s 34ms/step - loss: 0.0023 Epoch 2/8 330/331 [============================&gt;.] - ETA: 0s - loss: 0.0034WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss 331/331 [==============================] - 9s 28ms/step - loss: 0.0034 Epoch 3/8 330/331 [============================&gt;.] - ETA: 0s - loss: 3.2949e-04WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss 331/331 [==============================] - 10s 29ms/step - loss: 3.2849e-04 Epoch 4/8 330/331 [============================&gt;.] - ETA: 0s - loss: 7.3571e-05WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss 331/331 [==============================] - 10s 29ms/step - loss: 7.3349e-05 Epoch 5/8 331/331 [==============================] - ETA: 0s - loss: 7.5699e-06WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss 331/331 [==============================] - 10s 31ms/step - loss: 7.5699e-06 Epoch 6/8 331/331 [==============================] - ETA: 0s - loss: 2.0096e-05WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss 331/331 [==============================] - 9s 28ms/step - loss: 2.0096e-05 Epoch 7/8 331/331 [==============================] - ETA: 0s - loss: 7.2813e-05WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss 331/331 [==============================] - 9s 28ms/step - loss: 7.2813e-05 Epoch 8/8 331/331 [==============================] - ETA: 0s - loss: 3.8718e-06WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss 331/331 [==============================] - 10s 30ms/step - loss: 3.8718e-06 . &lt;keras.callbacks.History at 0x18d36df3100&gt; . . first_batch = scaled_train[-length:] . first_batch.shape . (120, 1) . first_batch = first_batch.reshape((1,length,n_features)) . Predictions using RNN . model.predict(first_batch) . array([[0.9499798]], dtype=float32) . scaled_test[0] . array([0.94955134]) . test_pred = [] first_batch = scaled_train[-length:] current_batch = first_batch.reshape((1,length,n_features)) for i in range(len(test)): current_pred = model.predict(current_batch)[0] test_pred.append(current_pred) current_batch = np.append(current_batch[:,1:,:],[[current_pred]],axis=1) . test_pred . [array([0.9499798], dtype=float32), array([0.9694884], dtype=float32), array([0.9844099], dtype=float32), array([0.99429387], dtype=float32), array([0.99932206], dtype=float32), array([0.9990793], dtype=float32), array([0.9939744], dtype=float32), array([0.9838967], dtype=float32), array([0.96927893], dtype=float32), array([0.95011795], dtype=float32), array([0.9268703], dtype=float32), array([0.899651], dtype=float32), array([0.86894196], dtype=float32), array([0.83496636], dtype=float32), array([0.7980918], dtype=float32), array([0.75866556], dtype=float32), array([0.71702135], dtype=float32), array([0.6735083], dtype=float32), array([0.62848186], dtype=float32), array([0.5823541], dtype=float32), array([0.5355599], dtype=float32), array([0.48840505], dtype=float32), array([0.44141504], dtype=float32), array([0.39500633], dtype=float32), array([0.34952673], dtype=float32), array([0.30553782], dtype=float32), array([0.26341128], dtype=float32), array([0.22366914], dtype=float32), array([0.18665712], dtype=float32), array([0.1528996], dtype=float32), array([0.12261443], dtype=float32), array([0.09634649], dtype=float32), array([0.07420367], dtype=float32), array([0.05664599], dtype=float32), array([0.0436875], dtype=float32), array([0.03566788], dtype=float32), array([0.03248379], dtype=float32), array([0.03440125], dtype=float32), array([0.04118868], dtype=float32), array([0.05296577], dtype=float32), array([0.06939272], dtype=float32), array([0.09044757], dtype=float32), array([0.11575846], dtype=float32), array([0.14512841], dtype=float32), array([0.17810209], dtype=float32), array([0.21435443], dtype=float32), array([0.2534281], dtype=float32), array([0.29491204], dtype=float32), array([0.3383421], dtype=float32), array([0.38326505], dtype=float32)] . predictions = scaler.inverse_transform(test_pred) . test[&#39;Prediction&#39;] = predictions . C: Users HP AppData Local Temp/ipykernel_10532/2447167120.py:1: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy test[&#39;Prediction&#39;] = predictions . test . Sine Prediction . 45.1 0.899097 | 0.899954 | . 45.2 0.938307 | 0.938971 | . 45.3 0.968142 | 0.968814 | . 45.4 0.988304 | 0.988582 | . 45.5 0.998591 | 0.998638 | . 45.6 0.998900 | 0.998152 | . 45.7 0.989229 | 0.987943 | . 45.8 0.969673 | 0.967787 | . 45.9 0.940429 | 0.938552 | . 46.0 0.901788 | 0.900230 | . 46.1 0.854137 | 0.853735 | . 46.2 0.797952 | 0.799297 | . 46.3 0.733794 | 0.737880 | . 46.4 0.662304 | 0.669929 | . 46.5 0.584197 | 0.596181 | . 46.6 0.500252 | 0.517329 | . 46.7 0.411309 | 0.434041 | . 46.8 0.318257 | 0.347016 | . 46.9 0.222024 | 0.256963 | . 47.0 0.123573 | 0.164709 | . 47.1 0.023888 | 0.071121 | . 47.2 -0.076037 | -0.023188 | . 47.3 -0.175201 | -0.117167 | . 47.4 -0.272615 | -0.209984 | . 47.5 -0.367305 | -0.300942 | . 47.6 -0.458325 | -0.388919 | . 47.7 -0.544766 | -0.473172 | . 47.8 -0.625764 | -0.552656 | . 47.9 -0.700509 | -0.626679 | . 48.0 -0.768255 | -0.694193 | . 48.1 -0.828324 | -0.754763 | . 48.2 -0.880118 | -0.807299 | . 48.3 -0.923117 | -0.851584 | . 48.4 -0.956893 | -0.886699 | . 48.5 -0.981108 | -0.912616 | . 48.6 -0.995521 | -0.928655 | . 48.7 -0.999986 | -0.935023 | . 48.8 -0.994460 | -0.931188 | . 48.9 -0.978997 | -0.917614 | . 49.0 -0.953753 | -0.894060 | . 49.1 -0.918979 | -0.861206 | . 49.2 -0.875023 | -0.819097 | . 49.3 -0.822324 | -0.768475 | . 49.4 -0.761408 | -0.709736 | . 49.5 -0.692885 | -0.643789 | . 49.6 -0.617439 | -0.571285 | . 49.7 -0.535823 | -0.493138 | . 49.8 -0.448854 | -0.410171 | . 49.9 -0.357400 | -0.323311 | . 50.0 -0.262375 | -0.233466 | . test.plot() . &lt;AxesSubplot:&gt; . Using LSTM . from tensorflow.keras.layers import LSTM . model = Sequential() model.add(LSTM(120,input_shape=(length,n_features))) model.add(Dense(1)) model.compile(optimizer=&#39;adam&#39;,loss=&#39;mse&#39;) . model.fit(generator,epochs = 8) . Epoch 1/8 331/331 [==============================] - 22s 59ms/step - loss: 0.0097 Epoch 2/8 331/331 [==============================] - 17s 52ms/step - loss: 5.3544e-04 Epoch 3/8 331/331 [==============================] - 17s 52ms/step - loss: 1.9293e-04 Epoch 4/8 331/331 [==============================] - 17s 52ms/step - loss: 2.2856e-04 Epoch 5/8 331/331 [==============================] - 17s 53ms/step - loss: 4.8776e-05 Epoch 6/8 331/331 [==============================] - 18s 53ms/step - loss: 6.8765e-05 Epoch 7/8 331/331 [==============================] - 18s 54ms/step - loss: 1.1893e-04 Epoch 8/8 331/331 [==============================] - 19s 58ms/step - loss: 9.0045e-04 . &lt;keras.callbacks.History at 0x18d394e4400&gt; . Predictions using LSTM . test_pred = [] first_batch = scaled_train[-length:] current_batch = first_batch.reshape((1,length,n_features)) for i in range(len(test)): current_pred = model.predict(current_batch)[0] test_pred.append(current_pred) current_batch = np.append(current_batch[:,1:,:],[[current_pred]],axis=1) . predictions = scaler.inverse_transform(test_pred) . test[&#39;LSTM Pred&#39;] = predictions . C: Users HP AppData Local Temp/ipykernel_10532/3796240138.py:1: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy test[&#39;LSTM Pred&#39;] = predictions . Comparing RNN and LSTM Predictions with the original label . test . Sine Prediction LSTM Pred . 45.1 0.899097 | 0.899954 | 0.930114 | . 45.2 0.938307 | 0.938971 | 0.970383 | . 45.3 0.968142 | 0.968814 | 1.003538 | . 45.4 0.988304 | 0.988582 | 1.029027 | . 45.5 0.998591 | 0.998638 | 1.046510 | . 45.6 0.998900 | 0.998152 | 1.055800 | . 45.7 0.989229 | 0.987943 | 1.056830 | . 45.8 0.969673 | 0.967787 | 1.049636 | . 45.9 0.940429 | 0.938552 | 1.034343 | . 46.0 0.901788 | 0.900230 | 1.011147 | . 46.1 0.854137 | 0.853735 | 0.980314 | . 46.2 0.797952 | 0.799297 | 0.942164 | . 46.3 0.733794 | 0.737880 | 0.897072 | . 46.4 0.662304 | 0.669929 | 0.845454 | . 46.5 0.584197 | 0.596181 | 0.787771 | . 46.6 0.500252 | 0.517329 | 0.724519 | . 46.7 0.411309 | 0.434041 | 0.656232 | . 46.8 0.318257 | 0.347016 | 0.583476 | . 46.9 0.222024 | 0.256963 | 0.506855 | . 47.0 0.123573 | 0.164709 | 0.427003 | . 47.1 0.023888 | 0.071121 | 0.344587 | . 47.2 -0.076037 | -0.023188 | 0.260305 | . 47.3 -0.175201 | -0.117167 | 0.174882 | . 47.4 -0.272615 | -0.209984 | 0.089069 | . 47.5 -0.367305 | -0.300942 | 0.003633 | . 47.6 -0.458325 | -0.388919 | -0.080646 | . 47.7 -0.544766 | -0.473172 | -0.162984 | . 47.8 -0.625764 | -0.552656 | -0.242605 | . 47.9 -0.700509 | -0.626679 | -0.318748 | . 48.0 -0.768255 | -0.694193 | -0.390677 | . 48.1 -0.828324 | -0.754763 | -0.457694 | . 48.2 -0.880118 | -0.807299 | -0.519144 | . 48.3 -0.923117 | -0.851584 | -0.574425 | . 48.4 -0.956893 | -0.886699 | -0.622995 | . 48.5 -0.981108 | -0.912616 | -0.664374 | . 48.6 -0.995521 | -0.928655 | -0.698152 | . 48.7 -0.999986 | -0.935023 | -0.723986 | . 48.8 -0.994460 | -0.931188 | -0.741607 | . 48.9 -0.978997 | -0.917614 | -0.750813 | . 49.0 -0.953753 | -0.894060 | -0.751478 | . 49.1 -0.918979 | -0.861206 | -0.743543 | . 49.2 -0.875023 | -0.819097 | -0.727022 | . 49.3 -0.822324 | -0.768475 | -0.701997 | . 49.4 -0.761408 | -0.709736 | -0.668621 | . 49.5 -0.692885 | -0.643789 | -0.627115 | . 49.6 -0.617439 | -0.571285 | -0.577771 | . 49.7 -0.535823 | -0.493138 | -0.520949 | . 49.8 -0.448854 | -0.410171 | -0.457082 | . 49.9 -0.357400 | -0.323311 | -0.386672 | . 50.0 -0.262375 | -0.233466 | -0.310290 | . test.plot() . &lt;AxesSubplot:&gt; . Since the sequence of the data is not long, RNN has performed better. However for Data having lengthy Sequence, use of LSTM would be an optimal choice. . Forecasting . full_scaler = MinMaxScaler() scaled_data = full_scaler.fit_transform(df) . length = 120 n_features = 1 . generator = TimeseriesGenerator(data=scaled_data,targets=scaled_data,length=length,batch_size=1) . model = Sequential() model.add(SimpleRNN(120,input_shape=(length,n_features))) model.add(Dense(1)) model.compile(optimizer=&#39;adam&#39;, loss=&#39;mse&#39;) . model.fit(generator,epochs=8) . Epoch 1/8 381/381 [==============================] - 12s 28ms/step - loss: 0.0061 Epoch 2/8 381/381 [==============================] - 13s 33ms/step - loss: 6.7171e-05 Epoch 3/8 381/381 [==============================] - 11s 28ms/step - loss: 7.7792e-04 Epoch 4/8 381/381 [==============================] - 10s 27ms/step - loss: 2.3956e-05 Epoch 5/8 381/381 [==============================] - 10s 27ms/step - loss: 2.7966e-05 Epoch 6/8 381/381 [==============================] - 11s 28ms/step - loss: 2.9440e-04 Epoch 7/8 381/381 [==============================] - 11s 28ms/step - loss: 6.4102e-06 Epoch 8/8 381/381 [==============================] - 11s 28ms/step - loss: 1.4723e-05 . &lt;keras.callbacks.History at 0x18d382f98e0&gt; . forecast = [] first_batch = scaled_data[-length:] current_batch = first_batch.reshape((1,length,n_features)) for i in range(len(test)): current_pred = model.predict(current_batch)[0] forecast.append(current_pred) current_batch = np.append(current_batch[:,1:,:],[[current_pred]],axis=1) . forecast = full_scaler.inverse_transform(forecast) . len(forecast) . 50 . forecast_index = np.arange(50.1,55.1,0.1) . Forecasting using RNN . plt.plot(df.index,df[&#39;Sine&#39;]) plt.plot(forecast_index,forecast) . [&lt;matplotlib.lines.Line2D at 0x18d3ce1e490&gt;] . Forecasting using LSTM . model = Sequential() model.add(LSTM(120,input_shape=(length,n_features))) model.add(Dense(1)) model.compile(optimizer=&#39;adam&#39;, loss=&#39;mse&#39;) . model.fit(generator,epochs=8) . Epoch 1/8 381/381 [==============================] - 24s 57ms/step - loss: 0.0065 Epoch 2/8 381/381 [==============================] - 20s 53ms/step - loss: 8.6971e-04 Epoch 3/8 381/381 [==============================] - 20s 52ms/step - loss: 1.5827e-04 Epoch 4/8 381/381 [==============================] - 20s 52ms/step - loss: 4.5681e-05 Epoch 5/8 381/381 [==============================] - 20s 51ms/step - loss: 5.7769e-05 Epoch 6/8 381/381 [==============================] - 20s 52ms/step - loss: 1.3684e-04 Epoch 7/8 381/381 [==============================] - 21s 56ms/step - loss: 8.3852e-04 Epoch 8/8 381/381 [==============================] - 21s 54ms/step - loss: 8.2290e-05 . &lt;keras.callbacks.History at 0x18d3a7617f0&gt; . forecast = [] first_batch = scaled_data[-length:] current_batch = first_batch.reshape((1,length,n_features)) for i in range(len(test)): current_pred = model.predict(current_batch)[0] forecast.append(current_pred) current_batch = np.append(current_batch[:,1:,:],[[current_pred]],axis=1) . plt.plot(df.index,df[&#39;Sine&#39;]) plt.plot(forecast_index,forecast) . [&lt;matplotlib.lines.Line2D at 0x18d4014adc0&gt;] . This shows that for data with large sequence LSTM is an optimal choice, however we can improve the model performance by increasing the number of epochs which currently has been trained at 8 epochs. .",
            "url": "https://bilalkhan18.github.io/port/2022/09/15/SineWave.html",
            "relUrl": "/2022/09/15/SineWave.html",
            "date": " • Sep 15, 2022"
        }
        
    
  
    
        ,"post2": {
            "title": "Medical Insurance Prediction",
            "content": "import numpy as np import pandas as pd import matplotlib.pyplot as plt import seaborn as sns . df = pd.read_csv(&#39;C: Users HP Downloads archive (97) insurance.csv&#39;) . . age: age of primary beneficiary . sex: insurance contractor gender, female, male . bmi: Body mass index, providing an understanding of body, weights that are relatively high or low relative to height, objective index of body weight (kg / m ^ 2) using the ratio of height to weight, ideally 18.5 to 24.9 . children: Number of children covered by health insurance / Number of dependents . smoker: Smoking . region: the beneficiary&#39;s residential area in the US, northeast, southeast, southwest, northwest. . charges: Individual medical costs billed by health insurance . df.head() . age sex bmi children smoker region charges . 0 19 | female | 27.900 | 0 | yes | southwest | 16884.92400 | . 1 18 | male | 33.770 | 1 | no | southeast | 1725.55230 | . 2 28 | male | 33.000 | 3 | no | southeast | 4449.46200 | . 3 33 | male | 22.705 | 0 | no | northwest | 21984.47061 | . 4 32 | male | 28.880 | 0 | no | northwest | 3866.85520 | . df.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 1338 entries, 0 to 1337 Data columns (total 7 columns): # Column Non-Null Count Dtype -- -- 0 age 1338 non-null int64 1 sex 1338 non-null object 2 bmi 1338 non-null float64 3 children 1338 non-null int64 4 smoker 1338 non-null object 5 region 1338 non-null object 6 charges 1338 non-null float64 dtypes: float64(2), int64(2), object(3) memory usage: 73.3+ KB . df.describe().transpose() . count mean std min 25% 50% 75% max . age 1338.0 | 39.207025 | 14.049960 | 18.0000 | 27.00000 | 39.000 | 51.000000 | 64.00000 | . bmi 1338.0 | 30.663397 | 6.098187 | 15.9600 | 26.29625 | 30.400 | 34.693750 | 53.13000 | . children 1338.0 | 1.094918 | 1.205493 | 0.0000 | 0.00000 | 1.000 | 2.000000 | 5.00000 | . charges 1338.0 | 13270.422265 | 12110.011237 | 1121.8739 | 4740.28715 | 9382.033 | 16639.912515 | 63770.42801 | . numeric_data = df[[&#39;age&#39;,&#39;bmi&#39;,&#39;children&#39;,&#39;charges&#39;]] . EDA . sns.displot(data=numeric_data, x=&#39;bmi&#39;,kind=&#39;kde&#39;) . &lt;seaborn.axisgrid.FacetGrid at 0x1ea7c43c8e0&gt; . sns.displot(data=numeric_data, x=&#39;age&#39;,kind=&#39;kde&#39;) . &lt;seaborn.axisgrid.FacetGrid at 0x1ea7c4124c0&gt; . sns.displot(data=numeric_data, x=&#39;charges&#39;) . &lt;seaborn.axisgrid.FacetGrid at 0x1ea7d878af0&gt; . numeric_data[&#39;children&#39;].value_counts() . 0 574 1 324 2 240 3 157 4 25 5 18 Name: children, dtype: int64 . plt.figure(figsize=(10,6),dpi=120) sns.countplot(data=df, x=&#39;children&#39;) . &lt;AxesSubplot:xlabel=&#39;children&#39;, ylabel=&#39;count&#39;&gt; . We shall consider these as categories and create a label of &#39;3 or more&#39; which includes rows having 3,4 and 5 children . correlation = numeric_data.corr() plt.figure(figsize=(8,6),dpi=120) sns.heatmap(data=correlation) . &lt;AxesSubplot:&gt; . numeric_data.corr()[&#39;charges&#39;].sort_values() . children 0.067998 bmi 0.198341 age 0.299008 charges 1.000000 Name: charges, dtype: float64 . plt.figure(figsize=(8,6),dpi=120) sns.scatterplot(data=df, x=&#39;age&#39;,y=&#39;charges&#39;) . &lt;AxesSubplot:xlabel=&#39;age&#39;, ylabel=&#39;charges&#39;&gt; . plt.figure(figsize=(8,6),dpi=120) sns.scatterplot(data=df, x=&#39;age&#39;,y=&#39;charges&#39;,hue=&#39;smoker&#39;) . &lt;AxesSubplot:xlabel=&#39;age&#39;, ylabel=&#39;charges&#39;&gt; . Insight 01: People who smoke have higher charges as comapared to non-smokers of the same age group . df.head() . age sex bmi children smoker region charges . 0 19 | female | 27.900 | 0 | yes | southwest | 16884.92400 | . 1 18 | male | 33.770 | 1 | no | southeast | 1725.55230 | . 2 28 | male | 33.000 | 3 | no | southeast | 4449.46200 | . 3 33 | male | 22.705 | 0 | no | northwest | 21984.47061 | . 4 32 | male | 28.880 | 0 | no | northwest | 3866.85520 | . plt.figure(figsize=(8,6),dpi=120) sns.scatterplot(data=df, x=&#39;age&#39;,y=&#39;charges&#39;,hue=&#39;sex&#39;) . &lt;AxesSubplot:xlabel=&#39;age&#39;, ylabel=&#39;charges&#39;&gt; . Insight 02: With increase of age, charges also increase regardless of gender. . plt.figure(figsize=(8,6),dpi=120) sns.scatterplot(data=df, x=&#39;children&#39;,y=&#39;charges&#39;) . &lt;AxesSubplot:xlabel=&#39;children&#39;, ylabel=&#39;charges&#39;&gt; . Insight 03: Number of children alone do not impact charges . plt.figure(figsize=(8,6),dpi=120) sns.scatterplot(data=df, x=&#39;bmi&#39;,y=&#39;charges&#39;,hue=&#39;sex&#39;,alpha=0.8) . &lt;AxesSubplot:xlabel=&#39;bmi&#39;, ylabel=&#39;charges&#39;&gt; . Insight 04: There is a slight linear increase in charges with increase in bmi . plt.figure(figsize=(8,6),dpi=120) sns.scatterplot(data=df,x=&#39;bmi&#39;,y=&#39;charges&#39;,hue=&#39;smoker&#39;) . &lt;AxesSubplot:xlabel=&#39;bmi&#39;, ylabel=&#39;charges&#39;&gt; . Insight 05: A person who smokes will have more charges as comapred to non-smoker of the same bmi . df.head() . age sex bmi children smoker region charges . 0 19 | female | 27.900 | 0 | yes | southwest | 16884.92400 | . 1 18 | male | 33.770 | 1 | no | southeast | 1725.55230 | . 2 28 | male | 33.000 | 3 | no | southeast | 4449.46200 | . 3 33 | male | 22.705 | 0 | no | northwest | 21984.47061 | . 4 32 | male | 28.880 | 0 | no | northwest | 3866.85520 | . def personality_check(bmi): if bmi &lt;= 18.5: return &#39;underweight&#39; elif (24.9 &gt; bmi &gt; 18.5): return &#39;normal&#39; elif (29.9&gt;bmi&gt;25): return &#39;overweight&#39; elif(bmi&gt;= 30): return &#39;obese&#39; df[&#39;personality&#39;] = df[&#39;bmi&#39;].apply(personality_check) . df.head() . age sex bmi children smoker region charges personality . 0 19 | female | 27.900 | 0 | yes | southwest | 16884.92400 | overweight | . 1 18 | male | 33.770 | 1 | no | southeast | 1725.55230 | obese | . 2 28 | male | 33.000 | 3 | no | southeast | 4449.46200 | obese | . 3 33 | male | 22.705 | 0 | no | northwest | 21984.47061 | normal | . 4 32 | male | 28.880 | 0 | no | northwest | 3866.85520 | overweight | . def smoke_personality(personality,smoker): if personality == &#39;obese&#39; and smoker == &#39;yes&#39;: return 1 else: return 0 df[&#39;obese_smoker&#39;] = df[[&#39;personality&#39;,&#39;smoker&#39;]].apply(lambda df: smoke_personality(df[&#39;personality&#39;],df[&#39;smoker&#39;]),axis=1) . df[df[&#39;obese_smoker&#39;]==1] . age sex bmi children smoker region charges personality obese_smoker . 14 27 | male | 42.130 | 0 | yes | southeast | 39611.75770 | obese | 1 | . 19 30 | male | 35.300 | 0 | yes | southwest | 36837.46700 | obese | 1 | . 23 34 | female | 31.920 | 1 | yes | northeast | 37701.87680 | obese | 1 | . 29 31 | male | 36.300 | 2 | yes | southwest | 38711.00000 | obese | 1 | . 30 22 | male | 35.600 | 0 | yes | southwest | 35585.57600 | obese | 1 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | . 1300 45 | male | 30.360 | 0 | yes | southeast | 62592.87309 | obese | 1 | . 1301 62 | male | 30.875 | 3 | yes | northwest | 46718.16325 | obese | 1 | . 1308 25 | female | 30.200 | 0 | yes | southwest | 33900.65300 | obese | 1 | . 1313 19 | female | 34.700 | 2 | yes | southwest | 36397.57600 | obese | 1 | . 1323 42 | female | 40.370 | 2 | yes | southeast | 43896.37630 | obese | 1 | . 145 rows × 9 columns . df.head() . age sex bmi children smoker region charges personality obese_smoker . 0 19 | female | 27.900 | 0 | yes | southwest | 16884.92400 | overweight | 0 | . 1 18 | male | 33.770 | 1 | no | southeast | 1725.55230 | obese | 0 | . 2 28 | male | 33.000 | 3 | no | southeast | 4449.46200 | obese | 0 | . 3 33 | male | 22.705 | 0 | no | northwest | 21984.47061 | normal | 0 | . 4 32 | male | 28.880 | 0 | no | northwest | 3866.85520 | overweight | 0 | . plt.figure(figsize=(8,6),dpi=120) sns.scatterplot(data=df,x=&#39;bmi&#39;,y=&#39;charges&#39;,hue=&#39;personality&#39;) . &lt;AxesSubplot:xlabel=&#39;bmi&#39;, ylabel=&#39;charges&#39;&gt; . plt.figure(figsize=(8,6),dpi=120) sns.scatterplot(data=df,x=&#39;bmi&#39;,y=&#39;charges&#39;,hue=&#39;obese_smoker&#39;) . &lt;AxesSubplot:xlabel=&#39;bmi&#39;, ylabel=&#39;charges&#39;&gt; . Feature Engineering . df.head() . age sex bmi children smoker region charges personality obese_smoker . 0 19 | female | 27.900 | 0 | yes | southwest | 16884.92400 | overweight | 0 | . 1 18 | male | 33.770 | 1 | no | southeast | 1725.55230 | obese | 0 | . 2 28 | male | 33.000 | 3 | no | southeast | 4449.46200 | obese | 0 | . 3 33 | male | 22.705 | 0 | no | northwest | 21984.47061 | normal | 0 | . 4 32 | male | 28.880 | 0 | no | northwest | 3866.85520 | overweight | 0 | . df[&#39;children&#39;] = df[&#39;children&#39;].astype(str) . def child(number): if (number == &#39;4&#39; or number == &#39;5&#39;): return &#39;3+&#39; else: return number df[&#39;children&#39;] = df[&#39;children&#39;].apply(child) . plt.figure(figsize=(10,6),dpi=120) sns.countplot(data=df, x=&#39;children&#39;) . &lt;AxesSubplot:xlabel=&#39;children&#39;, ylabel=&#39;count&#39;&gt; . df.head() . age sex bmi children smoker region charges personality obese_smoker . 0 19 | female | 27.900 | 0 | yes | southwest | 16884.92400 | overweight | 0 | . 1 18 | male | 33.770 | 1 | no | southeast | 1725.55230 | obese | 0 | . 2 28 | male | 33.000 | 3 | no | southeast | 4449.46200 | obese | 0 | . 3 33 | male | 22.705 | 0 | no | northwest | 21984.47061 | normal | 0 | . 4 32 | male | 28.880 | 0 | no | northwest | 3866.85520 | overweight | 0 | . plt.figure(figsize=(8,4),dpi=120) sns.boxplot(data=df,x=&#39;bmi&#39;) . &lt;AxesSubplot:xlabel=&#39;bmi&#39;&gt; . df[df[&#39;bmi&#39;]&gt;50] . age sex bmi children smoker region charges personality obese_smoker . 847 23 | male | 50.38 | 1 | no | southeast | 2438.0552 | obese | 0 | . 1047 22 | male | 52.58 | 1 | yes | southeast | 44501.3982 | obese | 1 | . 1317 18 | male | 53.13 | 0 | no | southeast | 1163.4627 | obese | 0 | . df.drop([847,1047,1317],axis=0,inplace=True) . plt.figure(figsize=(8,4),dpi=120) sns.boxplot(data=df,x=&#39;bmi&#39;) . &lt;AxesSubplot:xlabel=&#39;bmi&#39;&gt; . df[df[&#39;bmi&#39;]&gt;47] . age sex bmi children smoker region charges personality obese_smoker . 116 58 | male | 49.06 | 0 | no | southeast | 11381.32540 | obese | 0 | . 286 46 | female | 48.07 | 2 | no | northeast | 9432.92530 | obese | 0 | . 401 47 | male | 47.52 | 1 | no | southeast | 8083.91980 | obese | 0 | . 543 54 | female | 47.41 | 0 | yes | southeast | 63770.42801 | obese | 1 | . 860 37 | female | 47.60 | 2 | yes | southwest | 46113.51100 | obese | 1 | . 1088 52 | male | 47.74 | 1 | no | southeast | 9748.91060 | obese | 0 | . df.drop([116,286,401,543,860,1088],axis=0,inplace=True) . plt.figure(figsize=(8,4),dpi=120) sns.boxplot(data=df,x=&#39;bmi&#39;) . &lt;AxesSubplot:xlabel=&#39;bmi&#39;&gt; . df.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; Int64Index: 1329 entries, 0 to 1337 Data columns (total 9 columns): # Column Non-Null Count Dtype -- -- 0 age 1329 non-null int64 1 sex 1329 non-null object 2 bmi 1329 non-null float64 3 children 1329 non-null object 4 smoker 1329 non-null object 5 region 1329 non-null object 6 charges 1329 non-null float64 7 personality 1312 non-null object 8 obese_smoker 1329 non-null int64 dtypes: float64(2), int64(2), object(5) memory usage: 136.1+ KB . from feature_engine.encoding import OneHotEncoder encoder = OneHotEncoder(variables=[&#39;sex&#39;,&#39;children&#39;,&#39;smoker&#39;,&#39;region&#39;,]) df = encoder.fit_transform(df) . X = df.drop(&#39;charges&#39;,axis=1) y = df[&#39;charges&#39;] . from sklearn.model_selection import train_test_split X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=101,shuffle=True) . X_train[&#39;personality&#39;].fillna(&#39;overweight&#39;,inplace=True) . C: Users HP Downloads Anaconda_new lib site-packages pandas core generic.py:6392: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy return self._update_inplace(result) . X_test[&#39;personality&#39;].fillna(&#39;overweight&#39;,inplace=True) . C: Users HP Downloads Anaconda_new lib site-packages pandas core generic.py:6392: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy return self._update_inplace(result) . X_train.isnull().sum() . age 0 bmi 0 personality 0 obese_smoker 0 sex_female 0 sex_male 0 children_0 0 children_1 0 children_3 0 children_2 0 children_3+ 0 smoker_yes 0 smoker_no 0 region_southwest 0 region_southeast 0 region_northwest 0 region_northeast 0 dtype: int64 . from feature_engine.encoding import OrdinalEncoder ordinal_encoder = OrdinalEncoder(&#39;ordered&#39;,variables=[&#39;personality&#39;]) X_train = ordinal_encoder.fit_transform(X_train,y_train) X_test = ordinal_encoder.transform(X_test) . ordinal_encoder.encoder_dict_ . {&#39;personality&#39;: {&#39;underweight&#39;: 0, &#39;normal&#39;: 1, &#39;overweight&#39;: 2, &#39;obese&#39;: 3}} . Model Selection . from sklearn.linear_model import LinearRegression, ElasticNet from sklearn.tree import DecisionTreeRegressor from sklearn.ensemble import RandomForestRegressor from sklearn.svm import SVR from sklearn.ensemble import AdaBoostRegressor from sklearn.ensemble import GradientBoostingRegressor from sklearn.model_selection import GridSearchCV . from sklearn.preprocessing import StandardScaler from sklearn.pipeline import Pipeline from sklearn.metrics import mean_absolute_error, r2_score from sklearn.model_selection import cross_val_score . scaler = StandardScaler() X_train = scaler.fit_transform(X_train) X_test = scaler.transform(X_test) . lr_model = LinearRegression() dt_model = DecisionTreeRegressor() rf_model = RandomForestRegressor() svm_model = SVR() adaboost_model = AdaBoostRegressor() gradientboost_model = GradientBoostingRegressor() elastic_net = ElasticNet() . models = [lr_model,dt_model,rf_model,svm_model,adaboost_model,gradientboost_model,elastic_net] . for i in models: i.fit(X_train,y_train) pred = i.predict(X_test) print(i,r2_score(y_test,pred)) . LinearRegression() 0.8575981747551504 DecisionTreeRegressor() 0.6927026516049192 RandomForestRegressor() 0.8348691937436138 SVR() -0.09323108313765038 AdaBoostRegressor() 0.7935061017123721 GradientBoostingRegressor() 0.8452379705187539 ElasticNet() 0.8207939329537015 . Metrics . for i in models: cv_score = cross_val_score(i,X_train,y_train,cv=10,scoring=&#39;r2&#39;) print(&quot;%s: %f &quot; % (i, cv_score.mean())) . LinearRegression(): 0.853135 DecisionTreeRegressor(): 0.707465 RandomForestRegressor(): 0.832795 SVR(): -0.105989 AdaBoostRegressor(): 0.768739 GradientBoostingRegressor(): 0.851339 ElasticNet(): 0.815726 . linear_pred = lr_model.predict(X_test) r2 = r2_score(y_test,linear_pred) . r2 . 0.8575981747551504 . mae = mean_absolute_error(y_test,linear_pred) . rmse = np.sqrt(mean_absolute_error(y_test,pred)) . Results = [[r2],[mae],[rmse]] . Result = pd.DataFrame(data=Results,index=[&#39;R2&#39;,&#39;MAE&#39;,&#39;RMSE&#39;],columns=[&#39;Scores&#39;]) . Result . Scores . R2 0.857598 | . MAE 2484.152515 | . RMSE 59.230400 | .",
            "url": "https://bilalkhan18.github.io/port/2022/09/12/Medical-Insurance.html",
            "relUrl": "/2022/09/12/Medical-Insurance.html",
            "date": " • Sep 12, 2022"
        }
        
    
  
    
        ,"post3": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://bilalkhan18.github.io/port/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post4": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://bilalkhan18.github.io/port/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "My name is Bilal Khan. I’m currently pursuing Engineering in Artificial Intelligence and Machine Learning (3rd year). Machine Learning has been exciting and this page reflects projects which are a result of self-learning. I strongly believe that artificial intelligence is a revolution and i’m keen in contributing to a better world through AI. Cheers. .",
          "url": "https://bilalkhan18.github.io/port/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://bilalkhan18.github.io/port/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}